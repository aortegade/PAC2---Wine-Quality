---
title: 'Tipología y Ciclo de Vida de los Datos: PRA2 - Análisis de Calidad del Vino'
author: "Autor: Alejandro Ortega de los Ríos"
date: "Junio 2022"
output:
  html_document:
    highlight: default
    number_sections: yes
    theme: cosmo
    toc: yes
    toc_depth: 2
  word_document: default
  pdf_document:
    highlight: zenburn
    toc: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
******
# Descripción del Dataset

```{r message= FALSE, warning=FALSE}
data <- read.csv('winequality.csv', sep = ',')
str(data)

any(is.null(data))
any(duplicated(data))


if (!require('ggplot2')) install.packages('ggplot2'); library('ggplot2')
if(!require('Rmisc')) install.packages('Rmisc'); library('Rmisc')
if(!require('dplyr')) install.packages('dplyr'); library('dplyr')
```

El dataset consta de 1599 registros con 12 variables, todas numéricas. No existen valores nulos, pero sí hay un único duplicado.
A continuación se definen las variables que componen el dataset (https://www.kaggle.com/uciml/red-wine-quality-cortez-et-al-2009):

+ **fixed.acidity (num)**: g(tartaric acid)/dm3

+ **volatile.acidity (num)**: g(acetic acid)/dm3

+ **citric.acidity (num)**: ácido cítrico en g/dm3

+ **residual.sugar (num)**: azúcar en g/dm3

+ **chlorides (num)**: g(sodium chloride)/dm3

+ **free.sulfur.dioxide (num)**: dióxido de sulfato libre en mg/m3

+ **total.sulfur.dioxide (num)**: dióxido de sulfato total en mg/dm3

+ **density (num)**: densidad en g/cm3.

+ **pH (num)**: pH del vino.

+ **sulphates (num)**: sulfatos. g(potassium sulphate)/dm3

+ **alcohol (num)**: porcentaje de alcohol.

+ **quality (int)**: calidad (de 0 a 14)


# Objetivo del análisis

El objetivo de la práctica consitirá en generar un modelo que sea capaz de predecir la calidad del vino (variable objetivo) en función de sus características. Para ello, se emplearán las distintas fases del ciclo de vida del dato impartidas en la asignatura.


# Visualización del dataset
A continuación se muestra un diagrama de barras con la variable objetivo, junto con el resto de variables:

```{r message= FALSE, warning=FALSE}
#Matriz de correlación
library("corrplot")
corrplot(cor(data), method = "circle")
cor(data, method = "spearman")[, c("quality")]

#Columna de correlación de quality
data$quality <- as.factor(data$quality)

#Visualización de variables
hist_list <- list()
bar_list <- list()
for(i in 1:(ncol(data))){
  col <- names(data)[i]
  
  ggp <- ggplot(data,aes(data[, i],fill=quality)) + geom_bar() +labs(x=toupper(col), y="COUNTS")+ guides(fill=guide_legend(title= "Quality"))
  bar_list[[i]] <- ggp
  
  plot(bar_list[[i]])
  
  if(i < 12){
    boxplot(data[, i] ~ data$quality)
  }
}
```

# Limpieza de datos
En la presentación de los datos se comprobó que no existen valores nulos. Sin embargo sí que existen valores duplicados. Será necesario eliminarlos:
```{r message= FALSE, warning=FALSE}
which(any(duplicated(data)))
data <- data[-c(1),]
nrow(data)
```

En vista a la visualización de datos en forma de diagramas de caja, se procede a mostrar los valores atípicos del dataset:
```{r message= FALSE, warning=FALSE}
boxplot.stats(data$volatile.acidity)$out
boxplot.stats(data$citric.acid)$out
boxplot.stats(data$sulphates)$out
boxplot.stats(data$alcohol)$out
```

Que estos valores sean atípicos no quiere decir que no sean válidos. Significa únicamente que son estadísticamente "atípicos".
Los valores mostrados son perfectamente válidos (véase el caso del alcohol, la graduación del vino es perfectamente posible).

Además, en vista al coeficiente de correlación de las variables (primer apartado), se descartan aquellas que no estén correlacionadas (**selección de datos**):
```{r message= FALSE, warning=FALSE}
data.clean <- subset(data, select = c("volatile.acidity", "citric.acid", "sulphates", "alcohol", "quality"))
data.clean$quality <- as.factor(data.clean$quality)

head(data.clean)
```

# Análisis de datos
En esta fase se pretende lo siguiente:

+ **Correlación de variables**: realizado en la fase anterior para usarlo como criterio de selección de datos.

+ **Pruebas de normalidad y homocedasticidad**: paso necesario para decidir cómo proceder en los siguientes tests y para determinar qué algoritmos son o no válidos para generar el modelo.

+ **Contrastes de hipótesis**: comparación de medias entre dos o más grupos.

+ **Generación y validación del modelo**: buscar un algoritmo adecuado, entrenarlo y obtener métricas de rendimiento.

En primer lugar, se va a efectuar pruebas de normalidad de las variables del dataset:
```{r message= FALSE, warning=FALSE}
shapiro.test(data.clean$volatile.acidity)
shapiro.test(data.clean$citric.acid)
shapiro.test(data.clean$sulphates)
shapiro.test(data.clean$alcohol)
```

Se observa que, dado un p-valor < 0.05, se descartan las hipótesis de normalidad para las cuatro variables.

A continuación se procede con un análisis de homocedasticidad para las mismas variables:
```{r message= FALSE, warning=FALSE}
fligner.test(volatile.acidity ~ quality, data = data.clean)
fligner.test(citric.acid ~ quality, data = data.clean)
fligner.test(sulphates ~ quality, data = data.clean)
fligner.test(alcohol ~ quality, data = data.clean)
```

Dado que p-valor < 0.05, se descarta la hipótesis nula y se puede asumir que existen diferencias de varianza entre las muestras.

A continuación se procede a realizar los siguientes contrastes de hipótesis (Empleo Kruskal-Test dado que no existe normalidad ni homocedasticidad en la varianza, además de ser una comparación múltiple de variables):

```{r message= FALSE, warning=FALSE}
kruskal.test(volatile.acidity ~ quality, data = data.clean)
kruskal.test(citric.acid ~ quality, data = data.clean)
kruskal.test(sulphates ~ quality, data = data.clean)
kruskal.test(alcohol ~ quality, data = data.clean)
```

Dado que p-valor < 0.05, se descarta la hipótesis nula y se puede asumir que existen diferencias significativass entre las muestras.


Por último se procede a crear un modelo. Para ello se va a escoger RandomForests.Se trata de un algoritmo dentro del tipo de ensambladores (aplica una serie de algoritmos débiles en conjunción y “votan” cual es la clase correcta para los datos de entrada). Lo que hace es un muestreo con reemplazo (conocido como Bootstrap), y para cada muestra entrena un árbol de decisión. Una vez entrenado el modelo, el conjunto de árboles votan la nueva predicción, siendo el voto mayoritario la predicción del bosque. 

En primer lugar se divide aleatoriamente el conjunto de datos en conjuntos de entrenamiento y test (proporciones 2/3 y 1/3 del total respectivamente):
```{r message= FALSE, warning=FALSE}
#División del dataset en training y test sets.
set.seed(42)
split_prop <- 3
indexes <- sample(1:nrow(data.clean), size = floor(((split_prop - 1) / split_prop) * nrow(data.clean)))

train <- data.clean[indexes,]
test <- data.clean[-indexes,]
```

A continuación se procede con el entrenamiento del modelo:

```{r message= FALSE, warning=FALSE}
attach(data.clean)

if(!require('pROC')) install.packages('pROC');
library('pROC')
if(!require('randomForest')) install.packages('randomForest');
library('randomForest')

#Generación del modelo
model <- randomForest(quality~., data = train, mtry=2, importance = TRUE, keep.forest = TRUE)
model

#Importancia de cada variable para el modelo generado
model$importance
varImpPlot(model)
```

En la última imagen se muestra la importancia de cada variable dentro del modelo.

# Representación de los resultados
Los objetivos del apartado son los siguientes:

+ Visualización la matriz de confusión

+ Representación de la curva ROC junto con el AUC asociado.


```{r message= FALSE, warning=FALSE}
predict <- predict(model, test)

#Matriz de Confusión
library(caret)
cm <- confusionMatrix(test$quality, predict)
cm <- as.data.frame(cm$table)

ggplot(data = cm, aes(x = Prediction, y = Reference)) + geom_tile(aes(fill = Freq), colour = "white") + scale_fill_gradient(low = "white", high = "steelblue", trans = "log") + geom_text(aes(x = Prediction, y = Reference, label = Freq))

#Calculo la AUC y muestro la ROC
roc(as.numeric(test$quality), as.numeric(predict), plot = TRUE, legacy.axes = TRUE, percent = TRUE, col = "#4daf4a", lwd = 2, print.auc = TRUE)
```

Por parte de la matriz de confusión, se deduce que se ha generado un modelo con una gran cantidad de falsos positivos (véase las predicciones de calidad = 6, que muchas resultan ser 5 o 7). A primera vista parece un modelo poco robusto.

En cuanto al AUC, podemos determinar el rendimiento de un modelo en función de su valor:

+ AUC ≤ 0.5: no discrimina.

+ 0.6 ≤ AUC < 0.8: discrimina adecuadamente.

+ AUC ≥ 0.8: discriminación excelente.

Por tanto, tenemos otra métrica que indica un bajo rendimiento del modelo.

# Exportación del dataset
A continuación se exporta el conjunto de datos en formato CSV:
```{r message= FALSE, warning=FALSE}
write.csv(data.clean, "quality_wine_clean.csv")
```

# Conclusiones
En vista a la matriz de correlaciones se pudo comprobar que se trata de un dataset bastante pobre, al haber pocas relaciones con la variable objetivo. Bastantes variables se descartaron por este motivo.

Se hicieron pruebas de normalidad y homocedasticidad, obteniendo como resultado la no-normalidad de las variables independientes y la diferencia estadística entre las varianzas de estas en función de quality.

Además se hicieron tests de contrastes de hipótesis (comparación de medidas a través de tests no paramétricos) de las distintas variables en función del nivel de calidad del vino.

Por último, se generó un modelo RandomForests, y que mediante el OOB, matriz de confusión y el AUC se concluyó que se trata de un modelo poco fiable. Para poder cumplir con los objetivos del estudio, hará falta un dataset con características del vino que estén fuertemente relacionadas con su nivel de calidad. 

